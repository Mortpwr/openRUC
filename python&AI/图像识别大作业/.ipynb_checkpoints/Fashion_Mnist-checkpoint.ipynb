{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discription: Fashion Mnist 图像分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionDataset(Dataset):\n",
    "    '''\n",
    "    定义Dataset:\n",
    "    - 用于加载训练和测试数据，请勿改动\n",
    "    - 返回一张图片(3维Tensor)以及对应的标签(0-9)\n",
    "    '''\n",
    "    def __init__(self,datadir,transform,is_train = True):\n",
    "        super().__init__()\n",
    "        self.datadir = datadir\n",
    "        self.img,self.label = self.load_data(self.datadir,is_train = is_train)\n",
    "        self.len_data = len(self.img)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        return self.transform(self.img[index]), self.label[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len_data\n",
    "    \n",
    "    def load_data(self,datadir,is_train):\n",
    "        dirname = os.path.join(datadir)\n",
    "        files = ['train-labels-idx1-ubyte.gz', 'train-images-idx3-ubyte.gz',\n",
    "            't10k-labels-idx1-ubyte.gz', 't10k-images-idx3-ubyte.gz']\n",
    "\n",
    "        paths = []\n",
    "        for fname in files:\n",
    "            paths.append(os.path.join(dirname,fname))\n",
    "        if is_train:\n",
    "\n",
    "            with gzip.open(paths[0], 'rb') as lbpath:\n",
    "                label = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n",
    "            with gzip.open(paths[1], 'rb') as imgpath:\n",
    "                img = np.frombuffer(imgpath.read(), np.uint8,\n",
    "                                   offset=16).reshape(len(label), 28, 28)\n",
    "        else:\n",
    "            with gzip.open(paths[2], 'rb') as lbpath:\n",
    "                label = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n",
    "\n",
    "            with gzip.open(paths[3], 'rb') as imgpath:\n",
    "                img = np.frombuffer(imgpath.read(), np.uint8,\n",
    "                                      offset=16).reshape(len(label), 28, 28)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        ***********请在此写入你的代码**********\n",
    "        定义模型\n",
    "        '''\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        *********请在此处输入你的代码*********\n",
    "        输入：input, 它的size是(batch_size, img_h, img_w, img_c)\n",
    "        输出（返回值）：output(预测值)，hidden(隐藏层的值)\n",
    "            * output的size是(batch_size, num_label)\n",
    "            \n",
    "        定义模型函数：\n",
    "            * 将输入经过卷积层和激活函数\n",
    "            * 使用pooling降低通道数\n",
    "            * 对卷积层的输出做适当的维度变换\n",
    "            * 用线性层将output映射到num_label的维度上\n",
    "            * 返回output\n",
    "        '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        创建模型和优化器，设置模型超参数\n",
    "        * 参数\n",
    "            * learning_rate\n",
    "            * epoches\n",
    "            * model_save_path\n",
    "            * device: cuda or cpu\n",
    "        * 模型\n",
    "            * 创建FashionMnistModel的实例，命名为model\n",
    "            * 定义optimizer\n",
    "            * 定义loss function\n",
    "        '''\n",
    "        self.lr = 0.01\n",
    "        self.epoches = 20\n",
    "        self.model_save_path = './model'\n",
    "        # 指定训练的device，优先使用GPU，GPU不可用时加载CPU\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  \n",
    "        self.model = FashionMnistModel().to(self.device)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        self.loss_function = nn.CrossEntropyLoss()\n",
    "    def _save_model(self, epoch):\n",
    "        \"\"\"\n",
    "        保存模型，用于训练时保存指定epoch的模型\n",
    "        \"\"\"\n",
    "        print('[INFO] Saving to %s/%s.pth' % (self.model_save_path, epoch))\n",
    "        torch.save(self.model.state_dict(), '%s/%s.pth' % (self.model_save_path, epoch))\n",
    "        \n",
    "    def _load_model(self, epoch):\n",
    "        \"\"\"\n",
    "        加载模型，用于加载指定epoch的模型。\n",
    "        目前代码中没有用到。\n",
    "        可以在训练到一半但中断了之后，自行修改代码，从最近的epoch加载，然后继续训练，以节省时间。\n",
    "        或者训练完毕后，下次再跑程序，就直接加载模型，省去训练时间。\n",
    "        \"\"\"\n",
    "        print('[INFO] Loading from %s_%s.pth' % (self.model_save_path, epoch))\n",
    "        self.model.load_state_dict(torch.load('%s/%s.pth' % (self.model_save_path, epoch), map_location=self.device))\n",
    "        \n",
    "    def train(self,train_loader,test_loader):\n",
    "        '''\n",
    "        训练函数\n",
    "        '''\n",
    "        self.model.train()\n",
    "        for epoch in range(self.epoches):\n",
    "            loss_list = []\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                data, target = data.to(self.device), target.long().to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.model(data)\n",
    "                loss = self.loss_function(output, target)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                loss_list.append(loss.item())\n",
    "                if batch_idx % 50 == 0:\n",
    "                    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                               100. * batch_idx / len(train_loader), loss.item()))\n",
    "            self.test(test_loader)\n",
    "            # 保存模型参数\n",
    "            if epoch+1 % 5 == 0:\n",
    "                self._save_model(epoch+1)\n",
    "    def test(self,test_loader):\n",
    "        '''\n",
    "        检验模型测试集上的效果\n",
    "        '''\n",
    "        self.model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(self.device), target.long().to(self.device)\n",
    "                output = self.model(data)\n",
    "                test_loss += self.loss_function(output, target).item()  # sum up batch loss\n",
    "                pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, len(test_loader.dataset),\n",
    "            100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义data loader\n",
    "train_dataset = FashionDataset('data',\n",
    "                         transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                         ])\n",
    "                        )\n",
    "                             \n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=320, shuffle=True, num_workers= 4)\n",
    "\n",
    "test_dataset = FashionDataset('data',\n",
    "                         transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                         ]),\n",
    "                        is_train = False\n",
    "                        )\n",
    "test_loader = DataLoader(test_dataset,batch_size=32, shuffle=False, num_workers= 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.309021\n",
      "Train Epoch: 0 [16000/60000 (27%)]\tLoss: 0.594331\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.499439\n",
      "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.426943\n",
      "\n",
      "Test set: Average loss: 0.0129, Accuracy: 8530/10000 (85%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.333611\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.393509\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.344496\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.351152\n",
      "\n",
      "Test set: Average loss: 0.0115, Accuracy: 8614/10000 (86%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.333343\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.319182\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.353701\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.251076\n",
      "\n",
      "Test set: Average loss: 0.0110, Accuracy: 8737/10000 (87%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.328663\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.356560\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.249810\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.310279\n",
      "\n",
      "Test set: Average loss: 0.0102, Accuracy: 8818/10000 (88%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.253855\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.218514\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.200688\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.246318\n",
      "\n",
      "Test set: Average loss: 0.0108, Accuracy: 8796/10000 (88%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.270471\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.232029\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.310585\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.262960\n",
      "\n",
      "Test set: Average loss: 0.0103, Accuracy: 8833/10000 (88%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.186485\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.202608\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.222751\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.236064\n",
      "\n",
      "Test set: Average loss: 0.0107, Accuracy: 8795/10000 (88%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.171496\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.218432\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.243882\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.300229\n",
      "\n",
      "Test set: Average loss: 0.0109, Accuracy: 8790/10000 (88%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.196893\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.223860\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.301856\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.221639\n",
      "\n",
      "Test set: Average loss: 0.0108, Accuracy: 8835/10000 (88%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.185408\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.327831\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.202728\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.192292\n",
      "\n",
      "Test set: Average loss: 0.0121, Accuracy: 8735/10000 (87%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.207335\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.223109\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.214919\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.201415\n",
      "\n",
      "Test set: Average loss: 0.0123, Accuracy: 8808/10000 (88%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.281127\n",
      "Train Epoch: 11 [16000/60000 (27%)]\tLoss: 0.160332\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.196316\n",
      "Train Epoch: 11 [48000/60000 (80%)]\tLoss: 0.233411\n",
      "\n",
      "Test set: Average loss: 0.0118, Accuracy: 8853/10000 (89%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.119882\n",
      "Train Epoch: 12 [16000/60000 (27%)]\tLoss: 0.179686\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.132541\n",
      "Train Epoch: 12 [48000/60000 (80%)]\tLoss: 0.196371\n",
      "\n",
      "Test set: Average loss: 0.0120, Accuracy: 8795/10000 (88%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.199350\n",
      "Train Epoch: 13 [16000/60000 (27%)]\tLoss: 0.194708\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.230467\n",
      "Train Epoch: 13 [48000/60000 (80%)]\tLoss: 0.191367\n",
      "\n",
      "Test set: Average loss: 0.0126, Accuracy: 8859/10000 (89%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.217699\n",
      "Train Epoch: 14 [16000/60000 (27%)]\tLoss: 0.208782\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.186465\n",
      "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.216791\n",
      "\n",
      "Test set: Average loss: 0.0138, Accuracy: 8781/10000 (88%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.196297\n",
      "Train Epoch: 15 [16000/60000 (27%)]\tLoss: 0.126071\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 0.165488\n",
      "Train Epoch: 15 [48000/60000 (80%)]\tLoss: 0.167557\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 8792/10000 (88%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.220164\n",
      "Train Epoch: 16 [16000/60000 (27%)]\tLoss: 0.252417\n",
      "Train Epoch: 16 [32000/60000 (53%)]\tLoss: 0.157911\n",
      "Train Epoch: 16 [48000/60000 (80%)]\tLoss: 0.164390\n",
      "\n",
      "Test set: Average loss: 0.0143, Accuracy: 8776/10000 (88%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.167797\n",
      "Train Epoch: 17 [16000/60000 (27%)]\tLoss: 0.209685\n",
      "Train Epoch: 17 [32000/60000 (53%)]\tLoss: 0.152063\n",
      "Train Epoch: 17 [48000/60000 (80%)]\tLoss: 0.188326\n",
      "\n",
      "Test set: Average loss: 0.0140, Accuracy: 8788/10000 (88%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.161339\n",
      "Train Epoch: 18 [16000/60000 (27%)]\tLoss: 0.122148\n",
      "Train Epoch: 18 [32000/60000 (53%)]\tLoss: 0.281657\n",
      "Train Epoch: 18 [48000/60000 (80%)]\tLoss: 0.153802\n",
      "\n",
      "Test set: Average loss: 0.0142, Accuracy: 8766/10000 (88%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.237805\n",
      "Train Epoch: 19 [16000/60000 (27%)]\tLoss: 0.134300\n",
      "Train Epoch: 19 [32000/60000 (53%)]\tLoss: 0.154833\n",
      "Train Epoch: 19 [48000/60000 (80%)]\tLoss: 0.154873\n",
      "\n",
      "Test set: Average loss: 0.0144, Accuracy: 8798/10000 (88%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "# 模型xunlian\n",
    "model.train(train_loader,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = FashionMnistModel()\n",
    "# 加载权重\n",
    "state_dict = torch.load(\"./model/15.pth\")\n",
    "model2.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FashionMinistModel(\n",
       "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
       "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model,img):\n",
    "    model.eval()\n",
    "    img = img.unsqueeze(dim = 0)\n",
    "    output = model(img)\n",
    "    pred = output.argmax(dim=1, keepdim=True)\n",
    "    return pred.squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Pullover')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img,label = test_dataset.__getitem__(20)\n",
    "pred = inference(model2,img)\n",
    "fig = plt.figure(figsize=(1,1))\n",
    "plt.imshow(np.squeeze(img), cmap='gray')\n",
    "plt.title(label_classes[pred])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
